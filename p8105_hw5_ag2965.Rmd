---
title: "p8105_hw5_ag2965"
author: "Aakriti Shukla"
date: "2022-11-07"
output: github_document
editor_options: 
  chunk_output_type: inline
---

Due date: November 16, 2022
```{r, include = FALSE}
library(tidyverse)
library(pwr)
library(stringr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
) 

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```



#Problem 1
First, we loaded the data and joined the individual files using the list.files and str_c() functions. We then iterated over file names and read in the data for each subject.
```{r}
longi_df = 
  tibble(
    files = list.files("data/"),
    path = str_c("data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(cols=c(data))

longi_df
```

We then tidied the result and manipulated file names to include the control arm and subject ID. We also made sure that weekly observations were tidied.
```{r}
tidy_df = 
  longi_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)

tidy_df
```

We then created 2 spaghetti plots to compare observations for control and experimental groups. We can see that for the control group, the outcome did not change or had a slight downward slope downward slope. For the experimental group, the outcome had a positive slope over time. These findings suggest that the experimental group experienced a change over time, while the control group did not.
```{r}
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)+
labs(x = "Week", y= "Outcome") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    ggtitle("Observations Over Time For Control and Experimental Arms")
```



#Problem 2


Homicide data in 50 large U.S. cities - The Washington Post data

Let's load the data. 
```{r}
homicides_df <- read.csv(url("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"))%>%
  janitor::clean_names()

homicides_df_total=homicides_df%>%
  janitor::clean_names()%>%
  count()

homicides_df_state=homicides_df%>%
  janitor::clean_names()%>%
  group_by(state)%>%
  summarize

homicides_df_city=homicides_df%>%
  janitor::clean_names()%>%
  group_by(city)%>%
  summarize
```


There are 50 cities and 27 states in this dataset. There are 52,179 total homicides represented in this dataset.The variables included in this dataframe include the case ID, the date the homicide was reported, the victim’s first and last name, age, race, and sex, as well as the the following regarding the location of the crime: the city and state and the latitude and longitude. There is also data on the disposition of the case, which includes closed without arrest, closed by arrest, and opened/no arrest. The  dataset has `r nrow(homicides_df)` rows and `r ncol(homicides_df)` columns.

Below, we have created a table with the number of unsolved and total homicides by city. Unsolved homicides are those that have a disposition of "Closed by arrest" or "Open/No arrest".
```{r}
unsolved_homicides=homicides_df%>%
  janitor::clean_names()%>%
    unite(city_state, c(city, state), sep = ", ")%>%
    mutate(
      city_state=case_when(city_state=="Tulsa, AL" ~ "Tulsa, OK", TRUE~city_state)
    )%>%
    group_by(city_state)%>%
    summarize(
      unsolved=sum(disposition=="Closed by arrest" | disposition=="Open/No arrest"),
      total=n())

unsolved_homicides%>%
  knitr::kable()
```

We then created a dataframe for homicides in Baltimore and used the prop.test function to estimate the proportion of homicides that are unsolved. 

```{r}
baltimore_homicides=unsolved_homicides%>%
  filter(city_state %in% "Baltimore, MD")
```

```{r}
prop_unsolved=function(x_sum, n_total) {

proptest_unsolved=
  prop.test(
        x=x_sum,
        n=n_total,
        conf.level = 0.95, 
        alternative=c("two.sided"),
        correct = TRUE)%>%
  broom::tidy()%>%
   select(estimate,conf.low,conf.high)

proptest_unsolved
}

prop_unsolved(pull(baltimore_homicides,unsolved), pull(baltimore_homicides,total))
```

We then used this function to for each of the cities in the dataset and extracted the proportion of unsolved homicides and the confidence interval for each using the purrr::map2 function. We also creatd a plot that shows the estimates and CIs for each city along with error bars. This plot shows us that the great majority of homicides are unsolved in all locations. The lowest proportion of unsolved homicides were in Denver, San Diego, and Albuquerque, and the highest were in Louisville, Oakland, and Pittsburgh.

```{r}
unsolved_cities=unsolved_homicides%>%
  mutate(
    prop_unsolved_df = 
      map2(.x = unsolved, .y = total, ~prop_unsolved(x = .x, n = .y))
  ) %>% 
  unnest(prop_unsolved_df)

unsolved_cities
  
  ggplot(data=unsolved_cities, aes(x = fct_reorder(city_state, estimate), y = estimate)) +
geom_point() +
labs(x = "Location", y= "Proportion") +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.5) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    ggtitle("Proportion of Unsolved Homicides by Location")
```




#Problem 3


We created a simulation to explore power in a one-sample t-test with the following design elements: n=30, σ=5, μ=0 and we generated 5000 datasets from the mode. For each dataset, we have saved μ̂  and the p-value arising from a test of H:μ=0 using α=0.05.I have repeated this for μ={1,2,3,4,5,6}.

```{r}
t_test_clean = function(df){
  out_df <- t.test(df,
         alternative = c("two.sided"),
         mu = 0,
         conf.level = 0.95) %>%
    broom::tidy()
  return(out_df)
}

generate_results = function(mu = 0,
                            sigma = 5,
                            n_iter = 50,
                            n_obs = 30){

new_list = list()



for (i in 1:n_iter) {
  temp_vec = rnorm(n = n_obs, mean = mu, sd = sigma)
  new_list[[i]] = temp_vec
}




stats_tib =
  tibble(
    data = new_list
  ) %>%
  mutate(
    ttest_results = map(.x = data, ~t_test_clean(.x))
  ) %>%
  unnest(ttest_results) %>%
  janitor::clean_names() %>%
  select(estimate, p_value)

fin_tib = stats_tib %>%
  mutate(
    rej = p_value < 0.05
  ) %>%
  summarize(
    tot = n(),
    tot_rej = sum(rej),
    prop_rej = tot_rej/tot,
    avg_mu_hat = mean(estimate)
  )
return(fin_tib)
}


generate_results()

new_tib =
  tibble(
    mu = c(0, 1, 2, 3, 4, 5, 6)
  ) %>%
  mutate(
    results = map(.x = mu, ~generate_results(mu = .x))) %>%
      unnest(results)

```


Below, I have made a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. I have found that as effect size increases, as does power. 

```{r}
power_test=new_tib%>%
  ggplot(aes(x = mu, y = prop_rej)) +
  geom_point(aes(color = mu))+
labs(x = "Mu", y= "Proportion Rejected") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    ggtitle("Power of test")

power_test

```

Below, I have  made a plot (left panel) showing the average estimate of μ̂  on the y axis and the true value of μ on the x axis. 
```{r}
mu_hat_estimate=new_tib%>%
    ggplot(aes(x = mu, y = avg_mu_hat)) +
  geom_point(aes(color = mu))+
labs(x = "Mu", y= "Estimate of Mu-hat") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    ggtitle("Mu-hat at True Values of Mu")

```

We then made a second plot with the average estimate of μ̂  only in samples for which the null was rejected on the y axis and the true value of μ on the x axis.
The sample average of mu-hat for across tests for which the null hypothesis is rejected is not  equal to the true value of mu because these samples were sufficiently different than mu, as this incldued only those values in which the null hypothesis was rejected. 


```{r}
t_test_clean = function(df){
  out_df <- t.test(df,
         alternative = c("two.sided"),
         mu = 0,
         conf.level = 0.95) %>%
    broom::tidy()
  return(out_df)
}

generate_results_rej = function(mu = 0,
                            sigma = 5,
                            n_iter = 50,
                            n_obs = 30){

new_list_rej = list()



for (i in 1:n_iter) {
  temp_vec = rnorm(n = n_obs, mean = mu, sd = sigma)
  new_list_rej[[i]] = temp_vec
}


stats_tib_rej =
  tibble(
    data = new_list_rej
  ) %>%
  mutate(
    ttest_results = map(.x = data, ~t_test_clean(.x))
  ) %>%
  unnest(ttest_results) %>%
  janitor::clean_names() %>%
  select(estimate, p_value)

fin_tib_rej = stats_tib_rej %>%
  mutate(
    rej = p_value < 0.05
  ) %>%
  summarize(
    tot = n(),
    tot_rej = sum(rej),
    prop_rej = tot_rej/tot,
    avg_mu_hat = mean(estimate)
  )
return(fin_tib_rej)
}


new_tib_rej =
  tibble(
    mu = c(0, 1, 2, 3, 4, 5, 6)
  ) %>%
  mutate(
    results_rej = map(.x = mu, ~generate_results_rej(mu = .x))) %>%
      unnest(results_rej)

rejected=new_tib_rej%>%
  ggplot(aes(x=mu,y=avg_mu_hat))+
  geom_point(aes(color=mu))
```

```{r}
rejected = new_tib_rej %>%
  ggplot(aes(x = mu, y = avg_mu_hat)) +
  geom_point(aes(color = mu))+
  labs(x = "Mu", y= "Estimate of Mu-hat") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    ggtitle("Mu-hat at Mu for Rejected Cases")

library(patchwork)
mu_hat_estimate + rejected
```

